{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "\n",
    "def course_info(link, serial_number, course_code):\n",
    "    info = []\n",
    "    info.append(serial_number)\n",
    "    info.append(course_code)\n",
    "    response = requests.request(\"GET\", url = link)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    all_trs = soup.find_all('table')\n",
    "    trs = all_trs[0].find_all('tr')\n",
    "\n",
    "    index = [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "    for i in range(len(index)):\n",
    "        if index[i] == 5:\n",
    "            try:\n",
    "                tds = trs[index[i]].find_all('td')\n",
    "                for td in tds:\n",
    "                    name_list = list(td.stripped_strings)\n",
    "                    name_list.append('')\n",
    "                    s = name_list[0]\n",
    "                    for j in range(len(name_list) - 2):\n",
    "                        s = s + ' ' + name_list[j + 1]\n",
    "                    info.append(s)\n",
    "            except:\n",
    "                info.append('無資料')\n",
    "        else:    \n",
    "            try:\n",
    "                tds = trs[index[i]].find_all('td')\n",
    "                for td in tds:\n",
    "                    s = td.text.replace('\\n', '').replace('\\t', '')\n",
    "                    info.append(s)\n",
    "            except:\n",
    "                info.append('無資料')\n",
    "    info.append(link)\n",
    "    return info\n",
    "\n",
    "def course_list(link):\n",
    "    tmp = []\n",
    "    response = requests.request(\"GET\", url = link)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    all_courses = soup.find_all('tbody')\n",
    "    for courses in all_courses:\n",
    "        course = courses.find_all('tr')\n",
    "        for cours in course:\n",
    "            tds = cours.find_all('td')\n",
    "            serial_number = tds[0].text[0:5]\n",
    "            course_code = tds[0].text[5:tds[0].size]\n",
    "            onclick = tds[-1].a.get(\"onclick\")\n",
    "            left = onclick.find(\"'\")\n",
    "            right = onclick.find(\"'\", left+1)\n",
    "            a = course_info('https://cis.ncu.edu.tw' + onclick[left+1:right], serial_number, course_code)\n",
    "            tmp.append(a)\n",
    "    #a = course_info('https://cis.ncu.edu.tw' + onclick[left+1:right])\n",
    "    return tmp\n",
    "    #print(len(course))\n",
    "    \n",
    "def course_page(link):\n",
    "    tmp = []\n",
    "    response = requests.request(\"GET\", url = link)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    div = soup.find_all('div', class_ = 'pagelinks')\n",
    "    if (div != []):\n",
    "        pages = div[0].find_all('a')\n",
    "        left = link.find(\"?\")  \n",
    "        for i in range(len(pages)):\n",
    "            a = course_list(link[0:left+1] + 'd-49489-p=' + str(i+1) + '&' + link[left+1:-1] + '0')\n",
    "            for data in a:\n",
    "                tmp.append(data)\n",
    "    else:\n",
    "        a = course_list(link)\n",
    "        for data in a:\n",
    "            tmp.append(data)\n",
    "\n",
    "    return tmp\n",
    "\n",
    "\n",
    "response = requests.request(\"GET\", url = 'https://cis.ncu.edu.tw/Course/main/query/byUnion')\n",
    "soup = bs(response.text, 'html.parser')\n",
    "li = soup.find_all('li')\n",
    "\n",
    "a = []\n",
    "count = 0\n",
    "for link in li:\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "    datas = course_page('https://cis.ncu.edu.tw' + link.a.get(\"href\"))\n",
    "    for data in datas:\n",
    "        dictionary = {\n",
    "            'Serial Number': data[0],\n",
    "            'Course Code': data[1],\n",
    "            'Semester': data[2],\n",
    "            'Department': data[3],\n",
    "            'Instructor': data[4],\n",
    "            'Course Name (Chinese)': data[5],\n",
    "            'Course Name (English)': data[6],\n",
    "            'Educational System': data[7],\n",
    "            'Credit': data[8],\n",
    "            'Teaching Goal': data[9],\n",
    "            'Teaching Content': data[10],\n",
    "            'Textbooks/References': data[11],\n",
    "            'Self-compiled Textbook/References Proportion': data[12],\n",
    "            'Way of Instruction': data[13],\n",
    "            'Grading': data[14],\n",
    "            'Office Hour': data[15],\n",
    "            'Teaching Weeks': data[16],\n",
    "            'Flexible learning week description': data[17],\n",
    "            'Course Domain': data[18],\n",
    "            'Syllabus Link': data[19]\n",
    "        }\n",
    "        a.append(dictionary)\n",
    "with open('output.json', 'w', encoding='utf8') as outfile:\n",
    "    json.dump(a, outfile, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
